z
?mvrnorm
matrix(c(1,rho,rho,1)
, nrow=2)
e = mvrnorm(N, mu=c(0,0), Sigma=matrix(c(1,rho,rho,1), nrow=2))
e
e1 = e[,1]
e1
e2
e2 = e[,2]
m = as.numeric(1 + x + 3*z + e1 > 0)
m
y = as.numeric(1 + x + z + m + e2 > 0)
y
est = biprobit(m~x+z, y~x+z+m)
library(MASS)
est = biprobit(m~x+z, y~x+z+m)
install.packages("endogeniety")
install.packages("endogeneity")
library(endogeneity)
est = biprobit(m~x+z, y~x+z+m)
print(est$estimates, digits=3)
# partially observed version of m
observed_pct = 0.2
m_p = m
m_p[sample(N, N*(1-observed_pct))] = NA
est_partial = biprobit_partial(m_p~x+z, y~x+z)
print(est_partial$estimates, digits=3)
est_partial
x
print(est_partial$estimates, digits=3)
r * P + u
dP_dt <- function(P, t, u){
r * P + u
}
cost <- function(u){
integrate(function(t) (P(t) - P_star)^2 + u^2, lower = 0, upper = T)$value
}
library(AER)
install.packages("AER")
library(AER)
data("CollegeDistance")
CollegeDistance
library(tidyverse)
as_tibble(CollegeDistance)
write.csv(CollegeDistance, "E:/Even 2023/ECON04C10/collegeDistance.csv")
?CollegeDistance
install.packages("ahp")
# Sample income data (replace this with your own dataset)
income <- c(1000, 1500, 2000, 2500, 3000)
# Sort the income data in ascending order
sorted_income <- sort(income)
# Calculate the cumulative share of income
cumulative_income <- cumsum(sorted_income)
sorted_income
cumulative_income
# Calculate the cumulative share of total income
cumulative_percentage <- cumulative_income / sum(income)
cumulative_percentage
# Calculate the Lorenz curve data points (X-axis and Y-axis)
lorenz_curve <- data.frame(
x = c(0, cumulative_percentage),
y = c(0, cumulative_percentage)
)
lorenz_curve
lorenz_curve$x[-1]
length(lorenz_curve$x)
lorenz_curve$x[-length(lorenz_curve$x)]
# Calculate area A
area_A <- sum((lorenz_curve$x[-1] - lorenz_curve$x[-length(lorenz_curve$x)]) *
(lorenz_curve$y[-1] + lorenz_curve$y[-length(lorenz_curve$y)]))
area_A
# Calculate area B
area_B <- 0.5 - area_A
area_B
# Calculate Gini coefficient
gini_coefficient <- area_A / (area_A + area_B)
print(gini_coefficient)
library(tidyverse)
who2
who
who %>%
pivot_longer(
cols = new_sp_m014:newrel_f65,
names_to = "key",
values_to = "cases",
values_drop_na = TRUE
)
who %>%
pivot_longer(
cols = new_sp_m014:newrel_f65,
names_to = "key",
values_to = "cases",
values_drop_na = TRUE
) %>%
mutate(
key = stringr::str_replace(key, "newrel", "new_rel")
)
who %>%
pivot_longer(
cols = new_sp_m014:newrel_f65,
names_to = "key",
values_to = "cases",
values_drop_na = TRUE
) %>%
mutate(
key = stringr::str_replace(key, "newrel", "new_rel")
) %>%
separate(key, c("new", "var", "sexage")) %>%
select(-new, -iso2, -iso3) %>%
separate(sexage, c("sex", "age"), sep = 1)
?separate()
who %>%
pivot_longer(
cols = new_sp_m014:newrel_f65,
names_to = "key",
values_to = "cases",
values_drop_na = TRUE
) %>%
mutate(
key = stringr::str_replace(key, "newrel", "new_rel")
) %>%
separate(key, c("new", "var", "sexage")) %>%
select(-new, -iso2, -iso3) %>%
separate(sexage, c("sex", "age"), sep = 1, convert = TRUE)
#Use the gapminder dataset to answer the following questions:
# 1. How many unique countries are included in the dataset?
library(gapminder)
#Use the gapminder dataset to answer the following questions:
# 1. How many unique countries are included in the dataset?
install.packages("gapmider")
#Use the gapminder dataset to answer the following questions:
# 1. How many unique countries are included in the dataset?
install.packages("gapminder")
library(gapminder)
gapminder
library(gaominder)
library(gapminder)
names(gapminder)
library(tidyverse)
unique(gapminder$country)
gapminder %>%
group_by(country) %>%
summarise(max(gdpPercap), min(gdpPercap))
gapminder %>%
arrange(gdpPercap) %>%
select(country, gdpPercap)
gapminder %>%
arrange(desc(gdpPercap)) %>%
select(country, gdpPercap)
View(gapminder)
gapminder %>%
group_by(country, year) %>%
summarise(mean(lifeExp))
gapminder %>%
group_by(continent) %>%
summarise(mean(lifeExp))
gapminder %>%
group_by(continent) %>%
summarise(mean(lifeExp)) -> region_lifeexp
region_lifeexp
gapminder %>%
filter(year %in% c( 1952, 1962, 1972, 1982, 1992, 2002))
gapminder %>%
filter(year %in% c( 1952, 1962, 1972, 1982, 1992, 2002)) %>%
group_by(continent, year)
gapminder %>%
filter(year %in% c( 1952, 1962, 1972, 1982, 1992, 2002)) %>%
group_by(continent, year) %>%
summarise(mean(lifeExp))
gapminder %>%
filter(year %in% c( 1952, 1962, 1972, 1982, 1992, 2002))
gapminder %>%
filter(year %in% c( 1952, 1962, 1972, 1982, 1992, 2002)) %>%
ggplot(aes(x = continent))+
geom_bar()
gapminder %>%
ggplot(aes(x = continent, y = gdpPercap))+
geom_boxplot()
gapminder %>%
select(lifeExp, gdpPercap) %>%
corr()
?corr()
?cor()
gapminder %>%
select(lifeExp, gdpPercap) %>%
cor()
gapminder %>%
group_by(continent) %>%
summarise(cor(lifeExp, gdpPercap))
gapminder %>%
ggplot(aes(lifeExp, gdpPercap))+
geom_point()
gapminder %>%
ggplot(aes(lifeExp, gdpPercap))+
geom_point(aes(group = continent))
gapminder %>%
ggplot(aes(lifeExp, gdpPercap))+
geom_point(aes(col = continent))
gapminder %>%
ggplot(aes(log(lifeExp), log(gdpPercap)))+
geom_point(aes(col = continent))
gapminder %>%
ggplot(aes(log(lifeExp), log(gdpPercap)))+
geom_point()+
facet_grid(~continent)
gapminder %>%
ggplot(aes(lifeExp, gdpPercap))+
geom_point()+
facet_grid(~continent)
gapminder %>%
ggplot(aes(gdpPercap, lifeExp))+
geom_point()+
facet_grid(~continent)
gapminder %>%
group_by(year,  continent) %>%
summarise(cor(lifeExp, gdpPercap))
gapminder %>%
group_by(continent, year) %>%
summarise(cor(lifeExp, gdpPercap))
gapminder %>%
filter(country == "India")
?geom_line
gapminder %>%
filter(country == "India") %>%
ggplot(aes(x = year))+
geom_line(aes(y = log(lifeExp)))
gapminder %>%
filter(country == "India") %>%
ggplot(aes(x = year))+
geom_line(aes(y = log(lifeExp)))+
geom_line(aes(y = log(gdpPercap)))
gapminder %>%
filter(country == "India") %>%
ggplot(aes(x = year))+
geom_line(aes(y = log(lifeExp)), col = "red")+
geom_line(aes(y = log(gdpPercap)))
iris
getwd()
write.csv(iris, "iris.csv")
84/28
library(AER)
data(Journals)
Journals
library(tidyverse)
Journals %>%
select(subs, price, citations, citeprice = price/citations)
Journals %>%
select(subs, price, citations) %>%
mutate(citeprice = price/citations)
Journals %>%
select(subs, price, citations) %>%
mutate(citeprice = price/citations) %>%
as_tibble()
journals1 <- Journals %>%
select(subs, price, citations) %>%
mutate(citeprice = price/citations) %>%
as_tibble()
mean(journals1$citeprice)
journals1 %>%
ggplot(aes(subs, citeprice))+
geom_point()
journals1 %>%
ggplot(aes(log(subs), log(citeprice)))+
geom_point()
# linear model
linear_model_1 <- lm(log(subs) ~ log(citeprice), data = journals1)
linear_model_1
summary(linear_model_1)
anova(linear_model_1)
journals1 %>%
ggplot(aes(subs)) %>%
geom_histogram()
?geom_histogram(stat = "")
journals1 %>%
ggplot(aes(subs)) +
geom_histogram()
# checking skewness
journals1 %>%
ggplot(aes(subs)) +
geom_freqpoly()
journals1 %>%
ggplot(aes(log(subs))) +
geom_freqpoly()
journals1 %>%
ggplot(aes(citeprice)) +
geom_freqpoly()
journals1 %>%
ggplot(aes(log(citeprice))) +
geom_freqpoly()
journals1 %>%
ggplot(aes(log(citeprice))) +
geom_freqpoly(bins = 100) # positively skewed
journals1 %>%
ggplot(aes(log(citeprice))) +
geom_freqpoly(bins = 1000) # positively skewed
journals1 %>%
ggplot(aes(log(citeprice))) +
geom_freqpoly(bins = 5) # positively sk0ewed
# checking skewness
journals1 %>%
ggplot(aes(subs)) +
geom_freqpoly(bins = 5)
journals1 %>%
ggplot(aes(log(subs))) +
geom_freqpoly(bins = 5)
journals1 %>%
ggplot(aes(citeprice)) +
geom_freqpoly(bins = 5)
journals1 %>%
ggplot(aes(log(citeprice))) +
geom_freqpoly(bins = 5) # positively sk0ewed
summary(linear_model_1)
anova(linear_model_1)
?anova()
library(sf)
districts_shp <- read_sf("DISTRICT_BOUNDARY.shp")
names(districts_shp)
setwd("C:/Users/pravesh/Desktop/Project2023-24")
districts_shp <- read_sf("DISTRICT_BOUNDARY.shp")
names(districts_shp)
plot(districts_shp$geometry)
districts_names_shp <- districts_shp$District
districts_names_shp
districts_names_nsso <- readxl::read_excel("master_dataset.xlsx", sheet = "district_name")
districts_names_nsso
districts_nsso <- readxl::read_excel("master_dataset.xlsx", sheet = "district_name")
districts_names_nsso <- districts_nsso$`District Name`
districts_names_shp
library(tidyverse)
districts_names_shp %>%
arrange()
districts_names_shp %>%
as_tibble()
districts_names_shp %>%
as_tibble() %>%
rename(names = value)
districts_names_shp %>%
as_tibble() %>%
rename(names = value) %>%
arrange(names)
districts_names_shp %>%
as_tibble() %>%
rename(names = value) %>%
arrange(names) %>%
mutate(names_clean = str_replace_all(">", "A") )
districts_names_shp %>%
as_tibble() %>%
rename(names = value) %>%
arrange(names) %>%
str_replace_all(">", "A") )
?str_replace_all
districts_names_shp %>%
as_tibble() %>%
rename(names = value) %>%
arrange(names) %>%
str_replace_all(names, ">", "A") )
districts_names_shp %>%
as_tibble() %>%
rename(names = value) %>%
arrange(names) %>%
str_replace_all(names[1], ">", "A") )
districts_names_shp %>%
as_tibble() %>%
rename(names = value) %>%
arrange(names) -> t
str_replace_all(t$names[1], ">", "A") )
str_replace_all(t$names[1], ">", "A")
for i in 1:nrow(t){
for (i in 1:nrow(t)){
t$names_cleaned <- str_replace_all(t$names[i], ">", "A")
}
t
print()
print(x)
print(x[i])
}
x[i] = str_replace_all(t$names[i], ">", "A")
t$names_cleaned[i] = str_replace_all(t$names[i], ">", "A")
for (i in 1:nrow(t)){
t$names_cleaned[i] = str_replace_all(t$names[i], ">", "A")
}
t
}
for (i in 1:nrow(t)){
t$names_cleaned[i] = str_replace_all(t$names[i], c'(">", "|"), c("A", "I"))
}
for (i in 1:nrow(t)){
t$names_cleaned[i] = str_replace_all(t$names[i], c(">", "|"), c("A", "I"))
}
t
warnings()
for (i in 1:nrow(t)){
t$names_cleaned[i] = str_replace(t$names[i], c(">", "|"), c("A", "I"))
}
t
for (i in 1:nrow(t)){
t$names_cleaned[i] = str_replace_all(t$names[i], c(">" = "A", "|" =  "I"))
}
t
?mgsub
library(mgsub)
?mgsub
for (i in 1:nrow(t)){
t$names_cleaned[i] = mgsub::mgsub(t$names[i], c(">", "|"), replacement = c("A","I"))
}
t
for (i in 1:nrow(t)){
t$names_cleaned[i] = mgsub::mgsub(t$names[i], c(">", "|"), replacement = c("A"))
}
t
t$names_cleaned[i] = mgsub::mgsub(t$names[i], c(">"), replacement = c("A"))
t
for (i in 1:nrow(t)){
t$names_cleaned[i] = mgsub::mgsub(t$names[i], c(">"), replacement = c("A"))
}
t
districts_names_shp <- districts_shp$District
districts_names_shp
?gsub
?mgsub
for (i in 1:nrow(t)){
t$names_cleaned[i] = mgsub::mgsub(string = t$names[i],
pattern = c(">", "\\|"), replacement = c("A", "I"))
}
t
for (i in 1:nrow(t)){
grepl(“[^A-Za-z0-9 ]”, t$names_cleaned)
?grepl
for (i in 1:nrow(t)){
grepl(“[^A-Za-z0-9 ]”, t$names_cleaned[i])
for (i in 1:nrow(t)){
grepl(“[^A-Za-z0-9]”, t$names_cleaned[i])
for (i in 1:nrow(t)){
grepl('[[:punct:]]', t$names_cleaned[i])
print()
}
for (i in 1:nrow(t)){
grepl('[[:punct:]]', x = t$names_cleaned[i])
print()
}
for (i in 1:nrow(t)){
grepl(pattern = '[[:punct:]]', x = t$names_cleaned[i])
}
for (i in 1:nrow(t)){
grepl(pattern = '[[:punct:]]', x = t$names_cleaned[i])
print()
}
for (i in 1:nrow(t)){
t$punc <- grepl(pattern = '[[:punct:]]', x = t$names_cleaned[i])
}
t
tab(t)
table(t)
for (i in 1:nrow(t)){
t$names_cleaned[i] = mgsub::mgsub(string = t$names[i],
pattern = c(">", "\\|", "\\@"), replacement = c("A", "I", "U"))
}
t
for (i in 1:nrow(t)){
t$punc <- grepl(pattern = '[[:punct:]]', x = t$names[i])
}
t
districts_names_shp %>%
as_tibble() %>%
rename(names = value) %>%
arrange(names) -> districts_names_shp_1
# clean the data
for (i in 1:nrow(districts_names_shp_1)){
districts_names_shp_1$names_cleaned[i] = mgsub::mgsub(sdistricts_names_shp_1ring = districts_names_shp_1$names[i],
pattern = c(">", "\\|", "\\@"), replacement = c("A", "I", "U"))
}
# clean the data
for (i in 1:nrow(districts_names_shp_1)){
districts_names_shp_1$names_cleaned[i] = mgsub::mgsub(string = districts_names_shp_1$names[i],
pattern = c(">", "\\|", "\\@"), replacement = c("A", "I", "U"))
}
districts_names_shp_1
?match()
districts_names_nsso <- districts_nsso$`District Name` %>%
str_to_upper(locale = "en")
districts_names_nsso
match(districts_names_shp_1$names_cleaned, districts_nsso$`District Name` )
districts_names_nsso <- districts_nsso$`District Name` %>%
str_to_upper(locale = "en") %>% arrange(`District Name`)
districts_names_nsso
districts_names_nsso <- districts_nsso$`District Name` %>%
str_to_upper(locale = "en") %>% arrange()
districts_names_nsso <- districts_nsso$`District Name` %>%
str_to_upper(locale = "en") %>% class()
districts_nsso$`District Name` %>%
str_to_upper(locale = "en") %>% class()
districts_names_nsso <- districts_nsso$`District Name` %>%
str_to_upper(locale = "en") %>% arrange_all()
districts_names_nsso <- districts_nsso$`District Name` %>%
str_to_upper(locale = "en")
districts_names_nsso
?sort
sort(c("a", "x", "b", "p"))
districts_names_nsso <- districts_nsso$`District Name` %>%
str_to_upper(locale = "en") %>% sort()
districts_names_nsso
match(districts_names_shp_1$names_cleaned, districts_names_nsso )
}
}
for (i in 1:nrow(districts_names_shp_1)){
for (j in 1:nrow(districts_names_nsso)){
districts_names_shp_1$final_district[i] <- if_else(districts_names_shp_1[i] %in% districts_names_nsso[j],
districts_names_shp_1[i],
"No")
}
}
